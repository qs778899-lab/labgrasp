# coding=utf-8
import os
import cv2
import numpy as np
import pyrealsense2 as rs
import time
import threading

def create_folder_with_date():
    """åˆ›å»ºæ—¶é—´æˆ³æ–‡ä»¶å¤¹"""
    folder_name = time.strftime("%Y%m%d_%H%M%S", time.localtime())
    os.makedirs(folder_name, exist_ok=True)
    return folder_name

class CreateRealsense:
    def __init__(self, device_id):
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.config.enable_device(device_id)
        
        # é…ç½®æµ
        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        self.config.enable_stream(rs.stream.infrared, 1, 640, 480, rs.format.y8, 30)
        self.config.enable_stream(rs.stream.infrared, 2, 640, 480, rs.format.y8, 30)
        
        # å¯åŠ¨ç®¡é“
        self.profile = self.pipeline.start(self.config)
        # å¯¹é½å¯¹è±¡ï¼šæ·±åº¦â†’å½©è‰²
        self.align = rs.align(rs.stream.color)
        
        # é…ç½®ä¼ æ„Ÿå™¨
        self._setup_sensor()
        
        # é¢„çƒ­ç›¸æœº
        for _ in range(30):
            self.pipeline.wait_for_frames()
        print("ç›¸æœºåˆå§‹åŒ–å®Œæˆ")
        
        # çº¿ç¨‹æ§åˆ¶
        self.running = False
        self.frame_lock = threading.Lock()
        self.frames = {'color': None, 'depth': None, 'ir1': None, 'ir2': None}
        self.save_counter = 1

    def _setup_sensor(self):
        """é…ç½®ä¼ æ„Ÿå™¨å‚æ•°"""
        sensor = self.profile.get_device().query_sensors()[0]
        sensor.set_option(rs.option.emitter_enabled, 0)
        
        depth_sensor = self.profile.get_device().first_depth_sensor()
        depth_scale = depth_sensor.get_depth_scale()
        print(f"æ·±åº¦ç¼©æ”¾å› å­: {depth_scale}")

    def get_frames(self):
        """è·å–æ‰€æœ‰å¸§æ•°æ®"""
        frames = self.pipeline.wait_for_frames()
        aligned_frames = self.align.process(frames)
        
        color_frame = aligned_frames.get_color_frame()
        depth_frame = aligned_frames.get_depth_frame()
        ir1_frame = aligned_frames.get_infrared_frame(1)
        ir2_frame = aligned_frames.get_infrared_frame(2)
        
        if not (color_frame and depth_frame and ir1_frame and ir2_frame):
            return None
            
        return {
            'color': np.asanyarray(color_frame.get_data()),
            'depth': np.asanyarray(depth_frame.get_data()),
            'ir1': np.asanyarray(ir1_frame.get_data()),
            'ir2': np.asanyarray(ir2_frame.get_data())
        }

    def _update_frames(self):
        """åå°æ›´æ–°å¸§æ•°æ®"""
        while self.running:
            frame_data = self.get_frames()
            if frame_data:
                with self.frame_lock:
                    self.frames = frame_data

    def _save_frames(self, save_dir):
        """ä¿å­˜å½“å‰å¸§"""
        with self.frame_lock:
            frames = self.frames.copy()
            
        if not all(frames.values()):
            return
            
        base_name = os.path.join(save_dir, f"{self.save_counter:04d}")
        
        # ä¿å­˜æ–‡ä»¶
        cv2.imwrite(f"{base_name}_rgb.jpg", frames['color'])
        cv2.imwrite(f"{base_name}_depth.png", frames['depth'])
        cv2.imwrite(f"{base_name}_ir1.png", frames['ir1'])
        cv2.imwrite(f"{base_name}_ir2.png", frames['ir2'])
        
        # ä¿å­˜æ·±åº¦å½©è‰²å›¾
        depth_colormap = cv2.applyColorMap(
            cv2.convertScaleAbs(frames['depth'], alpha=0.03), 
            cv2.COLORMAP_JET
        )
        cv2.imwrite(f"{base_name}_depthmap.png", depth_colormap)
        
        print(f"å·²ä¿å­˜ç¬¬ {self.save_counter} ç»„å›¾åƒ")
        self.save_counter += 1

    def show_frame(self):
        """æ˜¾ç¤ºå®æ—¶ç”»é¢"""
        self.running = True
        save_dir = None
        
        # å¯åŠ¨å¸§æ›´æ–°çº¿ç¨‹
        update_thread = threading.Thread(target=self._update_frames, daemon=True)
        update_thread.start()
        
        try:
            while self.running:
                with self.frame_lock:
                    frames = self.frames.copy()
                
                if not all(frames.values()):
                    time.sleep(0.01)
                    continue
                
                # åˆ›å»ºæ˜¾ç¤ºå›¾åƒ
                depth_colormap = cv2.applyColorMap(
                    cv2.convertScaleAbs(frames['depth'], alpha=0.03), 
                    cv2.COLORMAP_JET
                )
                
                display1 = np.hstack((frames['color'], depth_colormap))
                display2 = np.hstack((frames['ir1'], frames['ir2']))
                
                cv2.imshow("RGB & Depth", display1)
                cv2.imshow("IR1 & IR2", display2)
                
                key = cv2.waitKey(1) & 0xFF
                if key == 27 or cv2.getWindowProperty("RGB & Depth", cv2.WND_PROP_VISIBLE) < 1:
                    break
                elif key == ord('s'):
                    if save_dir is None:
                        save_dir = create_folder_with_date()
                        print(f"ä¿å­˜ç›®å½•: {save_dir}")
                    self._save_frames(save_dir)
                    
        finally:
            self.running = False
            cv2.destroyAllWindows()

    def release(self):
        """é‡Šæ”¾èµ„æº"""
        self.running = False
        self.pipeline.stop()

    def get_point_coordinate(self, window_name="select_point"):
        """
        æ˜¾ç¤ºå®æ—¶ç”»é¢ï¼Œå…è®¸ç”¨æˆ·ç‚¹å‡»è·å–è¯¥ç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸­çš„3Dåæ ‡
        
        Returns:
            dict: åŒ…å«ç‚¹å‡»ç‚¹çš„åƒç´ åæ ‡å’Œ3Dåæ ‡
                {
                    'pixel': (x, y),           # åƒç´ åæ ‡
                    'camera_coord': (X, Y, Z), # ç›¸æœºåæ ‡ç³»ä¸­çš„3Dåæ ‡ (ç±³)
                    'depth': depth_value       # æ·±åº¦å€¼ (ç±³)
                }
            å¦‚æœç”¨æˆ·å–æ¶ˆæˆ–å‡ºé”™ï¼Œè¿”å› None
        """
        click_data = {'clicked': False, 'x': 0, 'y': 0}
        selected_point = None
        
        def mouse_callback(event, x, y, flags, param):
            """é¼ æ ‡å›è°ƒå‡½æ•°"""
            if event == cv2.EVENT_LBUTTONDOWN:
                click_data['clicked'] = True
                click_data['x'] = x
                click_data['y'] = y
        
        # è·å–ç›¸æœºå†…å‚
        profile = self.pipeline.get_active_profile()
        color_stream = profile.get_stream(rs.stream.color)
        intrinsics = color_stream.as_video_stream_profile().get_intrinsics()
        
        print("=" * 60)
        print("ğŸ–±ï¸  äº¤äº’å¼åæ ‡é€‰æ‹©æ¨¡å¼")
        print("=" * 60)
        print("æ“ä½œè¯´æ˜:")
        print("  - é¼ æ ‡å·¦é”®ç‚¹å‡»: é€‰æ‹©ç›®æ ‡ç‚¹")
        print("  - ESCé”®: å–æ¶ˆå¹¶é€€å‡º")
        print("=" * 60)
        
        try:
            cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
            # æ˜¾ç¤ºä¸€å¸§ç©ºç™½å›¾åƒï¼Œç¡®ä¿çª—å£åˆ›å»ºæˆåŠŸ
            dummy_frame = np.zeros((50, 50, 3), dtype=np.uint8)
            cv2.imshow(window_name, dummy_frame)
            cv2.waitKey(1)
        except cv2.error as e:
            print(f"âŒ æ— æ³•åˆ›å»ºçª—å£: {e}")
            return None

        try:
            cv2.setMouseCallback(window_name, mouse_callback)
        except cv2.error as e:
            print(f"âŒ æ— æ³•è®¾ç½®é¼ æ ‡å›è°ƒ: {e}")
            cv2.destroyWindow(window_name)
            return None

        try:
            while True:
                # è·å–å½“å‰å¸§
                frame_data = self.get_frames()
                if frame_data is None:
                    time.sleep(0.01)
                    continue
                
                color = frame_data['color'].copy()
                depth = frame_data['depth']
                
                # ç»˜åˆ¶åå­—å‡†æ˜Ÿå’Œæç¤ºä¿¡æ¯
                h, w = color.shape[:2]
                cv2.line(color, (w//2 - 20, h//2), (w//2 + 20, h//2), (0, 255, 0), 1)
                cv2.line(color, (w//2, h//2 - 20), (w//2, h//2 + 20), (0, 255, 0), 1)
                cv2.putText(color, "Click to select point | ESC to cancel", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºç”»é¢
                cv2.imshow(window_name, color)

                # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»
                if click_data['clicked']:
                    px, py = click_data['x'], click_data['y']
                    
                    # è·å–ç‚¹å‡»ç‚¹çš„æ·±åº¦å€¼ï¼ˆå•ä½ï¼šæ¯«ç±³ï¼‰
                    depth_value_mm = depth[py, px]
                    depth_value_m = depth_value_mm / 1000.0  # è½¬æ¢ä¸ºç±³
                    
                    if depth_value_mm == 0:
                        print(f"âš ï¸  è­¦å‘Š: ç‚¹å‡»ç‚¹ ({px}, {py}) çš„æ·±åº¦å€¼ä¸º0ï¼Œè¯·é‡æ–°é€‰æ‹©")
                        click_data['clicked'] = False
                        continue
                    
                    # ä½¿ç”¨ç›¸æœºå†…å‚å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»ä¸‹çš„3Dåæ ‡
                    # rs2_deproject_pixel_to_point å‡½æ•°æ‰§è¡ŒåæŠ•å½±
                    camera_coord = rs.rs2_deproject_pixel_to_point(
                        intrinsics, [px, py], depth_value_m
                    )
                    
                    selected_point = {
                        'pixel': (px, py),
                        'camera_coord': tuple(camera_coord),
                        'depth': depth_value_m
                    }
                    
                    print("=" * 60)
                    print("âœ… å·²é€‰æ‹©ç‚¹:")
                    print(f"  åƒç´ åæ ‡: ({px}, {py})")
                    print(f"  æ·±åº¦å€¼: {depth_value_m:.4f} m")
                    print(f"  ç›¸æœºåæ ‡ç³» (X, Y, Z): ({camera_coord[0]:.4f}, {camera_coord[1]:.4f}, {camera_coord[2]:.4f}) m")
                    print("=" * 60)
                    
                    # åœ¨å›¾åƒä¸Šæ ‡è®°é€‰ä¸­çš„ç‚¹
                    cv2.circle(color, (px, py), 5, (0, 0, 255), -1)
                    cv2.putText(color, f"Selected: ({px},{py})", 
                               (px + 10, py - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                               0.5, (0, 0, 255), 2)
                    cv2.imshow(window_name, color)
                    cv2.waitKey(1000)  # æ˜¾ç¤º1ç§’
                    break
                
                # æŒ‰ESCé€€å‡º
                key = cv2.waitKey(1) & 0xFF
                if key == 27:  # ESC
                    print("âŒ ç”¨æˆ·å–æ¶ˆé€‰æ‹©")
                    break
                    
        finally:
            cv2.destroyWindow(window_name)
        
        return selected_point

def main():
    """æ˜¾ç¤ºå¯ç”¨çš„ RealSense è®¾å¤‡"""
    ctx = rs.context()
    devices = ctx.query_devices()
    
    print("å¯ç”¨çš„ RealSense è®¾å¤‡:")
    for i, dev in enumerate(devices):
        name = dev.get_info(rs.camera_info.name)
        serial = dev.get_info(rs.camera_info.serial_number)
        print(f"è®¾å¤‡ {i}: {name} - åºåˆ—å·: {serial}")

if __name__ == "__main__":
    main()
    device_id = input("è¯·è¾“å…¥è®¾å¤‡åºåˆ—å·: ")
    
    cam = CreateRealsense(device_id)
    try:
        cam.show_frame()
    finally:
        cam.release()
