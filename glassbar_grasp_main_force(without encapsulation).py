#!/usr/bin/env python3
import sys
sys.path.append("FoundationPose")
from estimater import *
from datareader import *
from dino_mask import get_mask_from_GD   
from create_camera import CreateRealsense
import cv2
import numpy as np
# import open3d as o3d
import pyrealsense2 as rs
# import torch
import time, os, sys
import json
import threading
from datetime import datetime
import gc
import torch
# from ultralytics.models.sam import Predictor as SAMPredictor
from simple_api import SimpleApi, ForceMonitor, ErrorMonitor
from dobot_gripper import DobotGripper
from transforms3d.euler import euler2mat, mat2euler
from scipy.spatial.transform import Rotation as R
import queue
from spatialmath import SE3, SO3
from grasp_utils import normalize_angle, extract_euler_zyx, print_pose_info
from calculate_grasp_pose_from_object_pose import execute_grasp_from_object_pose, detect_dent_orientation
import rospy
from std_msgs.msg import Float64MultiArray
from sensor_msgs.msg import Image
from cv_bridge import CvBridge



# ---------- æ‰‹çœ¼æ ‡å®š ----------
def load_hand_eye_calibration(json_path="hand_eye_calibration.json"):
    """ä»JSONæ–‡ä»¶åŠ è½½æ‰‹çœ¼æ ‡å®šçŸ©é˜µ"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    calibration = data['T_ee_cam']
    rotation_matrix = np.array(calibration['rotation_matrix'])
    translation_vector = calibration['translation_vector']
    return SE3.Rt(rotation_matrix, translation_vector, check=False)

# ä»ç›¸æœºåæ ‡ç³»åˆ°æœ«ç«¯æ‰§è¡Œå™¨åæ ‡ç³»çš„å˜æ¢çŸ©é˜µ
T_ee_cam = load_hand_eye_calibration()

# ---------- æœºæ¢°è‡‚ ----------
def init_robot():
    dobot = SimpleApi("192.168.5.1", 29999)
    dobot.clear_error()
    dobot.enable_robot()
    dobot.stop()
    # å¯åŠ¨åŠ›ä¼ æ„Ÿå™¨
    dobot.enable_ft_sensor(1)
    time.sleep(1)
    # åŠ›ä¼ æ„Ÿå™¨ç½®é›¶(ä»¥å½“å‰å—åŠ›çŠ¶æ€ä¸ºåŸºå‡†)
    dobot.six_force_home()
    time.sleep(1)
    # åŠ›ç›‘æ§çº¿ç¨‹
    # force_monitor = ForceMonitor(dobot)
    # force_monitor.start_monitoring()
    # error_monitor = ErrorMonitor(dobot)
    # error_monitor.start_monitoring()
    gripper = DobotGripper(dobot)
    gripper.connect(init=True)
    return dobot, gripper


#??? ros é…ç½®å¯ä»¥å°è£…è¿›å¦ä¸€ä¸ªå‡½æ•°é‡Œå—ï¼Ÿ
# ---------- ROSèŠ‚ç‚¹ ----------
class ROSSubscriberTest:
    def __init__(self):
        """åˆå§‹åŒ–ROSèŠ‚ç‚¹å’Œè®¢é˜…è€…"""
        rospy.init_node('ros_subscriber_test', anonymous=True)  ##ros node name åªæ˜¯å‘Šè¯‰ ROSï¼šâ€œæˆ‘è¿™ä¸ªèŠ‚ç‚¹å«ä»€ä¹ˆâ€ï¼Œä¸ä»»ä½•è¯é¢˜åæˆ–å‡½æ•°åæ²¡æœ‰ç›´æ¥ç»‘å®šå…³ç³»ï¼›ä¿æŒå”¯ä¸€æ€§å³å¯ã€‚
        
        # åˆå§‹åŒ–cv_bridgeç”¨äºå›¾åƒè½¬æ¢
        self.bridge = CvBridge()

        #mark: æ•´ä½“çš„rosæ¥æ”¶ä¿¡æ¯æ–¹æ¡ˆï¼š callback_function + ç¼“å­˜(atest_tracking_data,latest_image) + è®¿é—®å‡½æ•°(get_latest_tracking_data,get_latest_image)
        
        # ç¼“å­˜æœ€æ–°çš„tracking_data
        self.latest_tracking_data = {
            'angle_z_deg': 0.0,
            'b': 0.0,
            'x': 0.0,
            'y': 0.0,
            'timestamp': 0.0,
            'valid': False
        }
        self.data_lock = threading.Lock()
        
        # ç¼“å­˜æœ€æ–°çš„image
        self.latest_image = None
        self.image_timestamp = 0.0
        self.image_lock = threading.Lock()
        
        # ç¼“å­˜æœ€æ–°çš„åŸå§‹å›¾åƒï¼ˆç”¨äºå›¾åƒå¤„ç†ï¼‰
        self.latest_raw_image = None
        self.raw_image_timestamp = 0.0
        self.raw_image_lock = threading.Lock()

        
        # è®¢é˜…tracking_data topic
        self.tracking_sub = rospy.Subscriber(
            'tracking_data', #topic name: tracking_data
            Float64MultiArray, 
            self.tracking_callback #mark: callback_function 
        )
        
        # è®¢é˜…object_orientation topic  
        self.image_sub = rospy.Subscriber(
            'image_object_orientation', #topic name: image_object_orientation
            Image,
            self.image_callback
        )
        
        # è®¢é˜…raw_image topic (çº¯å‡€åŸå§‹å›¾åƒï¼Œç”¨äºå›¾åƒå¤„ç†)
        self.raw_image_sub = rospy.Subscriber(
            'raw_image', #topic name: raw_image
            Image,
            self.raw_image_callback
        )
        
        print("ROSè®¢é˜…è€…å·²å¯åŠ¨ï¼Œç­‰å¾…æ•°æ®...")
        
    def tracking_callback(self, msg):
        """å¤„ç†tracking_dataæ¶ˆæ¯"""
        if len(msg.data) >= 4:
            angle_z_deg = msg.data[0]
            b = msg.data[1] 
            x = msg.data[2]
            y = msg.data[3]

            with self.data_lock:
                self.latest_tracking_data.update({
                    'angle_z_deg': angle_z_deg,
                    'b': b,
                    'x': x,
                    'y': y,
                    'timestamp': time.time(),
                    'valid': True
                })
            
            # print(f"ğŸ“Š è·Ÿè¸ªæ•°æ®: è§’åº¦={angle_z_deg:.2f}Â°, æˆªè·={b:.6f}, ä½ç½®=({x:.6f}, {y:.6f})")
        else:
            pass
            # print(f"âš ï¸  è·Ÿè¸ªæ•°æ®æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›4ä¸ªå€¼ï¼Œå®é™…æ”¶åˆ°{len(msg.data)}ä¸ªå€¼")
    
    def image_callback(self, msg):
        """å¤„ç†object_orientationå›¾åƒæ¶ˆæ¯"""
        try:
            # print(f"[DEBUG] å›¾åƒå›è°ƒè¢«è§¦å‘ï¼æ¶ˆæ¯ç±»å‹: {type(msg)}")
            # print(f"[DEBUG] å›¾åƒç¼–ç : {msg.encoding}, å°ºå¯¸: {msg.width}x{msg.height}")
            
            # å°†ROSå›¾åƒæ¶ˆæ¯è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜å›¾åƒ
            with self.image_lock:
                self.latest_image = cv_image.copy()
                self.image_timestamp = time.time()
            
            # # æ˜¾ç¤ºå›¾åƒ
            # cv2.imshow("Object Orientation", cv_image)
            # cv2.waitKey(1)  # éé˜»å¡ç­‰å¾…ï¼Œå…è®¸å…¶ä»–å¤„ç†
            height, width = cv_image.shape[:2]
            # print(f"ğŸ–¼ï¸  æˆåŠŸæ¥æ”¶å¹¶ä¿å­˜å›¾åƒ: {width}x{height} pixels")
            
        except Exception as e:
            print(f"âŒ å›¾åƒå¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    def raw_image_callback(self, msg):
        """å¤„ç†raw_imageåŸå§‹å›¾åƒæ¶ˆæ¯"""
        try:
            # å°†ROSå›¾åƒæ¶ˆæ¯è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜åŸå§‹å›¾åƒ
            with self.raw_image_lock:
                self.latest_raw_image = cv_image.copy()
                self.raw_image_timestamp = time.time()
            
            height, width = cv_image.shape[:2]
            # print(f"ğŸ“· æˆåŠŸæ¥æ”¶åŸå§‹å›¾åƒ: {width}x{height} pixels")
            
        except Exception as e:
            # Fallback: æ‰‹åŠ¨è§£æROS Imageæ¶ˆæ¯ï¼ˆç»•è¿‡cv_bridgeçš„libffié—®é¢˜ï¼‰
            print(f"âŒ raw å›¾åƒå¤„ç†é”™è¯¯: {e}")
            
    
    #mark: åœ¨callback_functionåŸºç¡€ä¸Šï¼Œè®¿é—®ç¼“å­˜çš„æœ€æ–°æ•°æ®
    def get_latest_tracking_data(self):
        """è·å–æœ€æ–°çš„è·Ÿè¸ªæ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.data_lock:
            return self.latest_tracking_data.copy()
    
    def get_latest_image(self):
        """è·å–æœ€æ–°çš„å›¾åƒæ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.image_lock:
            if self.latest_image is not None:
                return self.latest_image.copy(), self.image_timestamp
            else:
                return None, 0.0
    
    def get_latest_raw_image(self):
        """è·å–æœ€æ–°çš„åŸå§‹å›¾åƒæ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.raw_image_lock:
            if self.latest_raw_image is not None:
                return self.latest_raw_image.copy(), self.raw_image_timestamp
            else:
                return None, 0.0
    
    def run(self):
        """è¿è¡Œè®¢é˜…è€…"""
        try:
            # éé˜»å¡ä¿æ´»å¾ªç¯ï¼šç­‰å¾…ROSäº‹ä»¶ï¼Œä½†ä¸ä¸»åŠ¨é€€å‡º
            while not rospy.is_shutdown():
                time.sleep(0.05)
        except KeyboardInterrupt:
            print("\n rosä¸­æ–­,æ­£åœ¨é€€å‡º...")


if __name__ == "__main__":
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = os.path.join("record_images_during_grasp", timestamp)
    os.makedirs(save_dir, exist_ok=True)
    # print(f"å›¾åƒå°†ä¿å­˜åˆ°: {save_dir}")
    
    # åˆ›å»ºè§’åº¦æ•°æ®è®°å½•æ–‡ä»¶
    angle_log_path = os.path.join(save_dir, "angle_log.csv")
    with open(angle_log_path, 'w') as f:
        f.write("frame,timestamp,angle_z_deg,detected_angles,avg_angle\n")
    # print(f"è§’åº¦æ•°æ®å°†ä¿å­˜åˆ°: {angle_log_path}")
    
    camera = CreateRealsense("231522072272") 
    # mesh_file = "mesh/cube.obj"
    mesh_file = "mesh/thin_cube.obj"
    debug = 0
    debug_dir = "debug"
    set_logging_format()
    set_seed(0)
    mesh = trimesh.load(mesh_file)
    #? openscadçš„å•ä½æ˜¯mmï¼Œ ä½†æ˜¯è½¬ä¸ºobjæ–‡ä»¶åå•ä½åˆå˜æˆmï¼Œæ‰€ä»¥è¿˜æ˜¯éœ€è¦è½¬æ¢ï¼
    mesh.vertices /= 1000 #! å•ä½è½¬æ¢é™¤ä»¥1000
    # mesh.vertices /= 3
    to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
    bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)

    # åˆå§‹åŒ–æœºæ¢°è‡‚
    dobot, gripper = init_robot()

    #? åˆå§‹åŒ–ROSè®¢é˜…è€…ï¼ˆåœ¨åå°daemonçº¿ç¨‹è¿è¡Œï¼Œä¸ä¼šé˜»å¡mainç¨‹åºï¼‰
    try:
        ros_subscriber = ROSSubscriberTest()
        ros_thread = threading.Thread(target=ros_subscriber.run, daemon=True)
        ros_thread.start()
        print("âœ… ROSè®¢é˜…è€…å·²åœ¨åå°å¯åŠ¨ï¼ˆéé˜»å¡æ¨¡å¼ï¼‰")
        time.sleep(1)  # çŸ­æš‚ç­‰å¾…ROSèŠ‚ç‚¹å¯åŠ¨
    except Exception as e:
        print(f"âš ï¸  ROSè®¢é˜…è€…å¯åŠ¨å¤±è´¥: {e}")
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å ä½å¯¹è±¡ï¼Œé˜²æ­¢åç»­ä»£ç å‡ºé”™
        class DummySubscriber:
            def get_latest_tracking_data(self):
                return {'valid': False, 'angle_z_deg': 0.0, 'b': 0.0, 'x': 0.0, 'y': 0.0, 'timestamp': 0.0}
        ros_subscriber = DummySubscriber()

    # åˆå§‹åŒ–è¯„åˆ†å™¨å’Œå§¿æ€ä¼˜åŒ–å™¨
    scorer = ScorePredictor() 
    refiner = PoseRefinePredictor()
    glctx = dr.RasterizeCudaContext()
    # åˆ›å»ºFoundationPoseä¼°è®¡å™¨
    est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, mesh=mesh, scorer=scorer, refiner=refiner, debug_dir=debug_dir, debug=debug, glctx=glctx)
    logging.info("estimator initialization done")
    # è·å–ç›¸æœºå†…å‚
    cam_k = np.loadtxt(f'cam_K.txt').reshape(3,3)

    
    try:
        frame_count = 0
        last_valid_pose = None  # ä¿å­˜ä¸Šä¸€æ¬¡æœ‰æ•ˆçš„pose
        last_valid_angle = None  # ä¿å­˜ä¸Šä¸€æ¬¡æœ‰æ•ˆçš„ROSè§’åº¦
        last_seen_ts = None  # ä¸Šä¸€æ¬¡ä½¿ç”¨çš„ROSæ—¶é—´æˆ³ï¼ˆtracking_dataï¼‰
        last_seen_img_ts = None  # ä¸Šä¸€æ¬¡ä½¿ç”¨çš„å›¾åƒæ—¶é—´æˆ³
        last_valid_detected_angles = None  # ä¿å­˜ä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„è§’åº¦åˆ—è¡¨
        last_valid_avg_angle = 0.0  # ä¿å­˜ä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„å¹³å‡è§’åº¦
        
        while True:
            # è·å–å½“å‰å¸§
            # color = camera.get_frames()['color']  #get_framesè·å–å½“å‰å¸§çš„æ‰€æœ‰æ•°æ®ï¼ˆRGBã€æ·±åº¦ã€çº¢å¤–ç­‰ï¼‰
            # depth = camera.get_frames()['depth']/1000
            # ir1 = camera.get_frames()['ir1']
            # ir2 = camera.get_frames()['ir2']
            frames = camera.get_frames()
            if frames is None:
                continue
            color = frames['color']  #get_framesè·å–å½“å‰å¸§çš„æ‰€æœ‰æ•°æ®ï¼ˆRGBã€æ·±åº¦ã€çº¢å¤–ç­‰ï¼‰
            depth = frames['depth']/1000
            ir1 = frames['ir1']
            ir2 = frames['ir2']

            color_path = os.path.join(save_dir, f"color_frame_{frame_count:06d}.png")
            print("befor foundation pose, color_shape: ", color.shape)
            cv2.imwrite(color_path, color)
            
            
            # æ¯éš”30å¸§è¿›è¡Œä¸€æ¬¡FoundationPoseæ£€æµ‹
            if frame_count % 15 == 0:
                #ä½¿ç”¨GroundingDINOè¿›è¡Œè¯­ä¹‰ç†è§£æ‰¾åˆ°ç‰©ä½“çš„ç²—ç•¥ä½ç½®ï¼ŒSAMè·å–ç‰©ä½“çš„ç›¸å¯¹ç²¾ç¡®æ©ç 
                mask = get_mask_from_GD(color, "red stirring rod")
                # mask = get_mask_from_GD(color, "Plastic dropper") 
                # mask = get_mask_from_GD(color, "long yellow bar")
                # mask = get_mask_from_GD(color, "long red bar")
                # print("mask_shape: ", mask.shape)
            
                cv2.imshow("mask", mask)
                cv2.imshow("color", color)
                pose = est.register(K=cam_k, rgb=color, depth=depth, ob_mask=mask, iteration=50)
                print(f"ç¬¬{frame_count}å¸§æ£€æµ‹å®Œæˆï¼Œpose: {pose}")
                center_pose = pose@np.linalg.inv(to_origin) #! è¿™ä¸ªæ‰æ˜¯ç‰©ä½“ä¸­å¿ƒç‚¹çš„Pose
                vis = draw_posed_3d_box(cam_k, img=color, ob_in_cam=center_pose, bbox=bbox)
                vis = draw_xyz_axis(color, ob_in_cam=center_pose, scale=0.1, K=cam_k, thickness=3, transparency=0, is_input_rgb=True)
                cv2.imshow('1', vis[...,::-1])
    
                mask_path = os.path.join(save_dir, f"mask_frame_{frame_count:06d}.png")
                vis_path = os.path.join(save_dir, f"vis_frame_{frame_count:06d}.png")
                cv2.imwrite(mask_path, mask)
                cv2.imwrite(vis_path, vis[...,::-1])                

                # cv2.waitKey(0) #waitKey(0) æ˜¯ä¸€ç§é˜»å¡
                # input("break001") #inputä¹Ÿæ˜¯ä¸€ç§é˜»å¡
                # print("break001")
                
                #? æ¸…ç†å†…å­˜ (è¿™ä¸ªæœ‰ç”¨å—ï¼Ÿ)
                torch.cuda.empty_cache()
                gc.collect()
 
                last_valid_pose = center_pose  # ä¿å­˜è¿™æ¬¡æ£€æµ‹çš„ç»“æœ
            else:
                # ä½¿ç”¨ä¸Šä¸€æ¬¡æ£€æµ‹çš„ç»“æœ
                center_pose = last_valid_pose
                # print(f"ç¬¬{frame_count}å¸§ä½¿ç”¨ä¸Šæ¬¡æ£€æµ‹ç»“æœ")
            

            print("center_pose_object: ", center_pose) 
            
            frame_count += 1

            if center_pose is not None:
                break

    except KeyboardInterrupt:
        print("\n[ç”¨æˆ·ä¸­æ–­] æ”¶åˆ°ç»ˆæ­¢ä¿¡å·")
    finally:
        cv2.destroyAllWindows()
        # dobot.disable_robot()


    key = cv2.waitKey(1)
    # if key == ord('q'):  # æŒ‰qé€€å‡º
    #     break
    # elif key == ord('a'):  # æŒ‰aæ‰§è¡ŒæŠ“å–
    #
    # init_position = 10
    # gripper.control(position=init_position, force=80, speed=10)


    #mark: è·å–ROSè·Ÿè¸ªæ•°æ®ï¼ˆéé˜»å¡ï¼‰
    tracking_data = ros_subscriber.get_latest_tracking_data()
    has_new_msg = tracking_data['valid'] and (
        last_seen_ts is None or tracking_data['timestamp'] > last_seen_ts
    )
    if has_new_msg:
        # æ”¶åˆ°æ–°ROSæ•°æ®ï¼Œæ›´æ–°å¹¶ä½¿ç”¨æœ€æ–°è§’åº¦
        angle_z_deg = tracking_data['angle_z_deg']
        last_valid_angle = angle_z_deg
        last_seen_ts = tracking_data['timestamp']
        print(f"ğŸ”„ ä½¿ç”¨ROSè·Ÿè¸ªè§’åº¦: {angle_z_deg:.2f}Â° ")
    else:
        # æ²¡æœ‰æ–°ROSæ•°æ®
        if last_valid_angle is not None:
            angle_z_deg = last_valid_angle
            print(f"ä½¿ç”¨ä¸Šæ¬¡ROSè§’åº¦: {angle_z_deg:.2f}Â° (å½“å‰æ— æ–°æ•°æ®)")
        else:
            angle_z_deg = -45  # æœé‡Œ
            print("ä»æœªæ¥æ”¶åˆ°ROSæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤è§’åº¦: -45Â°")


    # å°†center_poseè½¬æ¢ä¸ºnumpyæ•°ç»„
    center_pose_array = np.array(center_pose, dtype=float)
    
    # ------ä½¿ç”¨å°è£…å‡½æ•°æ‰§è¡ŒæŠ“å–------
    # é…ç½®æŠ“å–å‚æ•°
    z_xoy_angle = 0 # ç‰©ä½“ç»•zè½´æ—‹è½¬è§’åº¦
    vertical_euler = [-180, 0, -90]  # å‚ç›´å‘ä¸‹æŠ“å–çš„graspå§¿æ€çš„rx, ry, rz
    grasp_tilt_angle = 30  #  ç”±å‚ç›´å‘ä¸‹æŠ“å–æ—‹è½¬ä¸ºæ–œç€å‘ä¸‹æŠ“å–çš„graspå§¿æ€çš„æ—‹è½¬è§’åº¦ï¼š åŠ äº†30åº¦ä¼šæœå¤–æ—‹è½¬
    z_safe_distance= 39  #zæ–¹å‘çš„ä¸€ä¸ªå®‰å…¨è·ç¦»ï¼Œä¹Ÿæ˜¯ä¸ºäº†æŠ“å–ç‰©ä½“é ä¸Šçš„éƒ¨åˆ†ï¼Œå¯çµæ´»è°ƒæ•´
    
    # è°ƒç”¨å°è£…å‡½æ•°æ‰§è¡ŒæŠ“å–
    success, T_base_ee_ideal = execute_grasp_from_object_pose(
        center_pose_array=center_pose_array,
        dobot=dobot,
        gripper=gripper,
        T_ee_cam=T_ee_cam,
        z_xoy_angle=z_xoy_angle,
        vertical_euler=vertical_euler,
        grasp_tilt_angle=grasp_tilt_angle,
        angle_threshold=10.0,
        T_tcp_ee_z= -0.16, 
        T_safe_distance= 0.00, #å¯çµæ´»è°ƒæ•´
        z_safe_distance=z_safe_distance,
        gripper_close_pos=20,
        verbose=True
    )
    
    pose_now = dobot.get_pose()
    x_adjustment = 115
    z_adjustment = 180
    dobot.move_to_pose(pose_now[0]+x_adjustment, pose_now[1], pose_now[2]+z_adjustment, pose_now[3], pose_now[4], pose_now[5], speed=7, acceleration=1) 


    #mark: å¾ªç¯è·å–ROSåŸå§‹å›¾åƒå¹¶æ£€æµ‹æ–¹å‘ï¼Œç›´åˆ°æ£€æµ‹æˆåŠŸ
    print("\n" + "="*60)
    print("ğŸ” å¼€å§‹æ£€æµ‹ç»ç’ƒæ£’æ–¹å‘...")
    print("="*60)
    
    detected_angles = None
    avg_angle = 0.0
    detection_attempts = 0
    
    while True:
        detection_attempts += 1
        
        # è·å–ROSåŸå§‹å›¾åƒæ•°æ®
        raw_image, img_timestamp = ros_subscriber.get_latest_raw_image()
        has_new_image = raw_image is not None
        
        if has_new_image:
            # æ”¶åˆ°æ–°å›¾åƒï¼Œè¿›è¡Œæ–¹å‘æ£€æµ‹
            print(f"\nğŸ“· ç¬¬{detection_attempts}æ¬¡å°è¯•: æ£€æµ‹æ–°åŸå§‹å›¾åƒæ–¹å‘ (æ—¶é—´æˆ³: {img_timestamp:.2f})")
            detected_angles, avg_angle = detect_dent_orientation(raw_image, save_dir=save_dir)
            
            if detected_angles:
                last_valid_detected_angles = detected_angles
                last_valid_avg_angle = avg_angle
                last_seen_img_ts = img_timestamp
                print(f"æˆåŠŸæ£€æµ‹åˆ°ç‰©ä½“æœå‘è§’åº¦: {detected_angles}, å¹³å‡: {avg_angle:.2f}Â°")
                print("="*60)
                break  
            else:
                print("å½“å‰å›¾åƒæœªæ£€æµ‹åˆ°æ˜æ˜¾æ–¹å‘ç‰¹å¾ï¼Œç»§ç»­ç­‰å¾…...")
                time.sleep(0.1)  
        else:
            print(f"ç¬¬{detection_attempts}æ¬¡å°è¯•: ç­‰å¾…å›¾åƒæ•°æ®...")
            time.sleep(0.1)  
        
        # å¯é€‰ï¼šæœ€å¤§å°è¯•æ¬¡æ•°é™åˆ¶
        if detection_attempts >= 100:
            print(" è­¦å‘Š: è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°(100æ¬¡)ï¼Œä½¿ç”¨é»˜è®¤è§’åº¦")
            detected_angles = []
            avg_angle = 0.0
            break

    # è®°å½•angle_z_deg å’Œ detected_anglesåˆ°logæ–‡ä»¶
    with open(angle_log_path, 'a') as f:
        angles_str = str(detected_angles) if detected_angles is not None else "None"
        f.write(f"{frame_count},{time.time():.3f},{angle_z_deg:.2f},{angles_str},{avg_angle:.2f}\n")



#-----------å¼€å§‹è°ƒæ•´ç»ç’ƒæ£’å§¿æ€-------------------------------------------------------

    print("å¼€å§‹è°ƒæ•´ç»ç’ƒæ£’å§¿æ€è‡³å‚ç›´æ¡Œé¢å‘ä¸‹")
    pose_now = dobot.get_pose()
    delta_ee = avg_angle - grasp_tilt_angle
    #éœ€è¦è®©tcpæœå¤–æ—‹è½¬ï¼› grasp_tilt_angleä¸ºæ­£å€¼æ—¶ï¼Œtcpä¼šæœå¤–æ—‹è½¬ã€‚
    pose_target = [pose_now[0]+15, pose_now[1], pose_now[2], pose_now[3]+delta_ee, pose_now[4], pose_now[5]]
    dobot.move_to_pose(pose_target[0], pose_target[1], pose_target[2], pose_target[3], pose_target[4], pose_target[5], speed=12, acceleration=1)
    

    wait_rate = rospy.Rate(1.0 / 12.0)  
    wait_rate.sleep()
    
    # éªŒè¯æ˜¯å¦åˆ°è¾¾ç›®æ ‡ä½ç½®
    pose_after_adjust = dobot.get_pose()
    print(f"æ£€æŸ¥å§¿æ€è°ƒæ•´æ˜¯å¦å®Œæˆ: Rx={pose_after_adjust[3]:.2f}Â° (ç›®æ ‡: {pose_target[3]:.2f}Â°)")

    #å‚ç›´æ¡Œé¢å‘ä¸‹ç§»åŠ¨ç»ç’ƒæ£’ï¼Œæ£€æµ‹æ˜¯å¦è§¦ç¢°åˆ°æ¡Œé¢
    print("\nå¼€å§‹ç›‘æµ‹ç»ç’ƒæ£’ä¸æ¡Œé¢æ¥è§¦...")

    move_step = 1          # mm
    max_steps = 700
    sample_interval = 0.03  # ç§’
    max_force_samples = 30
    force_threshold = 1.0  # Nï¼Œè§¦ç¢°åˆ¤å®šé˜ˆå€¼
    consecutive_hits_required = 2

    pose_current = dobot.get_pose()
    contact_detected = False
    contact_force = 0.0

    for step in range(max_steps):
        wait = rospy.Rate(33)
        wait.sleep()

        pose_current[2] -= move_step
        dobot.move_to_pose(
            pose_current[0], pose_current[1], pose_current[2],
            pose_current[3], pose_current[4], pose_current[5],
            speed=5, acceleration=1
        )

        consecutive_hits = 0
        for _ in range(max_force_samples):
            short_wait = rospy.Rate(1/sample_interval)
            short_wait.sleep()
            force_values = dobot.get_force()
            if not force_values:
                continue

            print("force_values: ", force_values)
            

            max_force_component = max(abs(value) for value in force_values)
            if max_force_component >= force_threshold:
                consecutive_hits += 1
                contact_force = max_force_component
                if consecutive_hits >= consecutive_hits_required:
                    contact_detected = True
                    break
            else:
                consecutive_hits = 0

        if contact_detected:
            print(
                f"æ£€æµ‹åˆ°å—åŠ›å˜åŒ–ï¼ç»ç’ƒæ£’å¯èƒ½å·²æ¥è§¦æ¡Œé¢ (æ­¥æ•°: {step+1}, ä¸‹é™: {(step+1)*move_step}mm, Fzâ‰ˆ{contact_force:.2f}N)"
            )
            break

        print(f"  æ­¥éª¤ {step+1}/{max_steps}: æœªæ£€æµ‹åˆ°æ¥è§¦ï¼Œç»§ç»­ä¸‹é™...")
    else:
        print("è¾¾åˆ°å‚ç›´å‘ä¸‹æœ€å¤§ç§»åŠ¨è·ç¦»ï¼Œæœªæ£€æµ‹åˆ°æ˜æ˜¾å—åŠ›å˜åŒ–")

    print("ç»ç’ƒæ£’ä¸‹é™æ£€æµ‹å®Œæˆ\n")

        
    # å¯é€‰ï¼šè¿”å›homeä½ç½®ï¼ˆæ ¹æ®éœ€è¦å–æ¶ˆæ³¨é‡Šï¼‰
    # dobot.move_to_pose(435.4503, 281.809, 348.9125, -179.789, -0.8424, 14.4524, speed=9)

    #ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
    pose_now = dobot.get_pose()
    x_target, y_target, z_target= 450, -150, 12
    rx_target, ry_target, rz_target= pose_now[3], pose_now[4], pose_now[5]
    # dobot.move_to_pose(x_target, y_target, z_target, rx_target, ry_target, rz_target, speed=9)


